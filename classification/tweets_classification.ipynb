{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tweets_classification",
      "provenance": [],
      "collapsed_sections": [
        "vANUDvImA8l4",
        "ySHDqNfqBSJP",
        "AHHcwTymBfUI",
        "B1yBHV7jDAf_",
        "qg9dMKdXCAGY",
        "BUErCv_VE8yQ",
        "6U_S7Y4oLNUD",
        "sIOmhqVA_ZHi",
        "O0wQHas9bV01",
        "TSFA-oYpa9oq",
        "qlWG_4UhSMk4",
        "rgtHgcMihfn8",
        "lsxjz6XIq9Ck",
        "JjAFPFU6rZfv",
        "ar9LtqxNrfE3",
        "0X8EOh3TrjdT",
        "__5_idHvxUia",
        "6rnb72o5Ldbb",
        "dzKlT6B0HxKJ",
        "2_4pKW3QH1NA",
        "3Q0pMsK8RAaJ",
        "Rls6J5OgFkJC",
        "my_Dy333mpQO",
        "pVwFwi-4tWSA",
        "11JsbFQ1N_G0",
        "EGD19A_xOVfJ",
        "qXQrCxksOwLB",
        "SoC2ieB2PV34",
        "nSqySgEeRXfc",
        "s2D5ADb6MIIl",
        "6WzcMbGn4DEH",
        "b4pVVAJHMJag",
        "T58MFVCI8kdz",
        "_zs5tVUSQsZx",
        "ErRfS9lLQ10a",
        "TOOCrbNeRDVQ",
        "cZQnAmsBRGxe",
        "PdtHJ19aCEW5",
        "rj3Ibnem5abk",
        "2zcYYPuCCFbi",
        "4hqk7Y5gCG5x",
        "0_wApeL7VSUD",
        "kiVXaOOoVTyE",
        "uApEvVIvWAgc",
        "-JsAZ2dkWbTE",
        "QDpXvIHvWcVj",
        "R5fWnreGWhC4",
        "srs_r1L557W3",
        "PAkt2f-R58sY",
        "-fqVs3NZejAj",
        "tQlsI9S6yqB3",
        "SrF4PktAyvii",
        "wu8xjuBRzs2F",
        "d1rdETws8c2j",
        "XgLvwPI50yec",
        "5Ns9ArC38gqT",
        "VV-zOLwsKNWG",
        "Ovcr45DBFDTi"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vANUDvImA8l4"
      },
      "source": [
        "# Tweets Classification\n",
        "\n",
        "Will be used a keras deep learning model to classify the tweets between 1 (positive) or 0 (negative).\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySHDqNfqBSJP"
      },
      "source": [
        "# Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Hnu_qAYAl5U"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split,  RandomizedSearchCV\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.backend import clear_session\n",
        "\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras import layers"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHHcwTymBfUI"
      },
      "source": [
        "# Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEO9C4KgBkiw"
      },
      "source": [
        "df_nlp_tweets = pd.read_csv(\"/content/drive/MyDrive/DI - Analise Bitcoin - GPU/4. Execução/2. Analise de Sentimento/tweets_increase_nlp.csv\")\n",
        "\n",
        "df_nlp_tweets['Raise'] = df_nlp_tweets['Raise'].astype(int)\n",
        "df_nlp_tweets['Date'] = df_nlp_tweets['Date'].astype('datetime64[ns]')\n",
        "df_nlp_tweets['Data_processing_3'] = df_nlp_tweets['Data_processing_3'].astype(str)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1yBHV7jDAf_"
      },
      "source": [
        "## NLP Tweets dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "FmqSZ0zgCMZJ",
        "outputId": "9ac79de0-2f13-4944-ee46-56d26e24ba1d"
      },
      "source": [
        "df_nlp_tweets = df_nlp_tweets[['Tweet','Date', 'Raise', 'Data_processing_1', 'Data_processing_2', 'Data_processing_3', 'Data_processing_4','Data_processing_5']]\n",
        "df_nlp_tweets"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet</th>\n",
              "      <th>Date</th>\n",
              "      <th>Raise</th>\n",
              "      <th>Data_processing_1</th>\n",
              "      <th>Data_processing_2</th>\n",
              "      <th>Data_processing_3</th>\n",
              "      <th>Data_processing_4</th>\n",
              "      <th>Data_processing_5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Reasons why I'm bullish on #Bitcoin:\\n\\n About...</td>\n",
              "      <td>2021-10-18</td>\n",
              "      <td>1</td>\n",
              "      <td>reasons i'm bullish #bitcoin: retake ath bitco...</td>\n",
              "      <td>reasons i m bullish bitcoin retake ath bitcoin...</td>\n",
              "      <td>reasons bullish bitcoin retake ath bitcoin etf...</td>\n",
              "      <td>reason bullish bitcoin retak ath bitcoin etf a...</td>\n",
              "      <td>reason bullish bitcoin retak ath bitcoin etf a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>First U.S. #bitcoin ETF looks set to debut Tue...</td>\n",
              "      <td>2021-10-18</td>\n",
              "      <td>1</td>\n",
              "      <td>first u.s. #bitcoin etf looks set debut tuesda...</td>\n",
              "      <td>first u s bitcoin etf looks set debut tuesday ...</td>\n",
              "      <td>first u bitcoin etf looks set debut tuesday pr...</td>\n",
              "      <td>first u bitcoin etf look set debut tuesday pro...</td>\n",
              "      <td>first u bitcoin etf look set debut tuesday pro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Top10 Twitter KOL &amp; Gem Rating Oct.18\\n1 $DOGE...</td>\n",
              "      <td>2021-10-18</td>\n",
              "      <td>1</td>\n",
              "      <td>top10 twitter kol &amp; gem rating oct.18 1 $doge ...</td>\n",
              "      <td>top10 twitter kol gem rating oct 18 1 doge 2 x...</td>\n",
              "      <td>top10 twitter kol gem rating oct 18 1 doge 2 x...</td>\n",
              "      <td>top10 twitter kol gem rate oct 18 1 doge 2 xrp...</td>\n",
              "      <td>top10 twitter kol gem rate oct 18 1 doge david...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>#bitcoin over $62,000 again. \\n\\n$3,000 to go.</td>\n",
              "      <td>2021-10-18</td>\n",
              "      <td>1</td>\n",
              "      <td>#bitcoin $62,000 again. $3,000 go.</td>\n",
              "      <td>bitcoin 62 000 again 3 000 go</td>\n",
              "      <td>bitcoin 62 000 3 000 go</td>\n",
              "      <td>bitcoin 62 000 3 000 go</td>\n",
              "      <td>bitcoin 62 000 3 000 go</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Shiba Inu could Reach 50 Cents By December 202...</td>\n",
              "      <td>2021-10-18</td>\n",
              "      <td>1</td>\n",
              "      <td>shiba inu could reach 50 cents december 2022? ...</td>\n",
              "      <td>shiba inu could reach 50 cents december 2022 h...</td>\n",
              "      <td>shiba inu could reach 50 cents december 2022 m...</td>\n",
              "      <td>shiba inu could reach 50 cent decemb 2022 math...</td>\n",
              "      <td>shiba inu could reach 50 cent decemb 2022 math...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63313</th>\n",
              "      <td>\"\\n@IconicExpert\\n: @nomaxpi \\n@CryptoCobain\\n...</td>\n",
              "      <td>2014-09-17</td>\n",
              "      <td>0</td>\n",
              "      <td>\" @iconicexpert : @nomaxpi @cryptocobain im wo...</td>\n",
              "      <td>iconicexpert nomaxpi cryptocobain im worth tim...</td>\n",
              "      <td>iconicexpert nomaxpi cryptocobain im worth tim...</td>\n",
              "      <td>iconicexpert nomaxpi cryptocobain im worth tim...</td>\n",
              "      <td>iconicexpert nomaxpi cryptocobain im worth tim...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63314</th>\n",
              "      <td>Can someone send me their btc address? Theblon...</td>\n",
              "      <td>2014-09-17</td>\n",
              "      <td>0</td>\n",
              "      <td>someone send btc address? theblonde offered bi...</td>\n",
              "      <td>someone send btc address theblonde offered bit...</td>\n",
              "      <td>someone send btc address theblonde offered bit...</td>\n",
              "      <td>someon send btc address theblond offer bitcoin...</td>\n",
              "      <td>someon send btc address theblond offer bitcoin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63315</th>\n",
              "      <td>\"\\n@moolah_io\\n: @GambitBTC $VIA is on the fin...</td>\n",
              "      <td>2014-09-17</td>\n",
              "      <td>0</td>\n",
              "      <td>\" @moolah_io : @gambitbtc $via final list. ple...</td>\n",
              "      <td>moolah_io gambitbtc via final list please chec...</td>\n",
              "      <td>moolah_io gambitbtc via final list please chec...</td>\n",
              "      <td>moolah_io gambitbtc via final list pleas check...</td>\n",
              "      <td>moolah_io gambitbtc via final list pleas check...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63316</th>\n",
              "      <td>What if we all take out loans + buy bitcoin. D...</td>\n",
              "      <td>2014-09-17</td>\n",
              "      <td>0</td>\n",
              "      <td>take loans + buy bitcoin. default loans. cause...</td>\n",
              "      <td>take loans buy bitcoin default loans cause len...</td>\n",
              "      <td>take loans buy bitcoin default loans cause len...</td>\n",
              "      <td>take loan buy bitcoin default loan caus lend c...</td>\n",
              "      <td>take loan buy bitcoin default loan caus lend c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63317</th>\n",
              "      <td>Funny indicator for types of people in crypto:...</td>\n",
              "      <td>2014-09-17</td>\n",
              "      <td>0</td>\n",
              "      <td>funny indicator types people crypto: claim 're...</td>\n",
              "      <td>funny indicator types people claim really succ...</td>\n",
              "      <td>funny indicator types people claim really succ...</td>\n",
              "      <td>funni indic type peopl claim realli success prior</td>\n",
              "      <td>funni indic type peopl crypto claim realli suc...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>63318 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   Tweet  ...                                  Data_processing_5\n",
              "0      Reasons why I'm bullish on #Bitcoin:\\n\\n About...  ...  reason bullish bitcoin retak ath bitcoin etf a...\n",
              "1      First U.S. #bitcoin ETF looks set to debut Tue...  ...  first u bitcoin etf look set debut tuesday pro...\n",
              "2      Top10 Twitter KOL & Gem Rating Oct.18\\n1 $DOGE...  ...  top10 twitter kol gem rate oct 18 1 doge david...\n",
              "3         #bitcoin over $62,000 again. \\n\\n$3,000 to go.  ...                            bitcoin 62 000 3 000 go\n",
              "4      Shiba Inu could Reach 50 Cents By December 202...  ...  shiba inu could reach 50 cent decemb 2022 math...\n",
              "...                                                  ...  ...                                                ...\n",
              "63313  \"\\n@IconicExpert\\n: @nomaxpi \\n@CryptoCobain\\n...  ...  iconicexpert nomaxpi cryptocobain im worth tim...\n",
              "63314  Can someone send me their btc address? Theblon...  ...  someon send btc address theblond offer bitcoin...\n",
              "63315  \"\\n@moolah_io\\n: @GambitBTC $VIA is on the fin...  ...  moolah_io gambitbtc via final list pleas check...\n",
              "63316  What if we all take out loans + buy bitcoin. D...  ...  take loan buy bitcoin default loan caus lend c...\n",
              "63317  Funny indicator for types of people in crypto:...  ...  funni indic type peopl crypto claim realli suc...\n",
              "\n",
              "[63318 rows x 8 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qg9dMKdXCAGY"
      },
      "source": [
        "## Create a dataset with only tweets and raise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "4VauxS_0CFWf",
        "outputId": "a974e485-f097-47f0-dd16-c312785baa4a"
      },
      "source": [
        "df_tweets_raise = df_nlp_tweets[['Tweet', 'Raise']]\n",
        "df_tweets_raise"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet</th>\n",
              "      <th>Raise</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Reasons why I'm bullish on #Bitcoin:\\n\\n About...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>First U.S. #bitcoin ETF looks set to debut Tue...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Top10 Twitter KOL &amp; Gem Rating Oct.18\\n1 $DOGE...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>#bitcoin over $62,000 again. \\n\\n$3,000 to go.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Shiba Inu could Reach 50 Cents By December 202...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63313</th>\n",
              "      <td>\"\\n@IconicExpert\\n: @nomaxpi \\n@CryptoCobain\\n...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63314</th>\n",
              "      <td>Can someone send me their btc address? Theblon...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63315</th>\n",
              "      <td>\"\\n@moolah_io\\n: @GambitBTC $VIA is on the fin...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63316</th>\n",
              "      <td>What if we all take out loans + buy bitcoin. D...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63317</th>\n",
              "      <td>Funny indicator for types of people in crypto:...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>63318 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   Tweet  Raise\n",
              "0      Reasons why I'm bullish on #Bitcoin:\\n\\n About...      1\n",
              "1      First U.S. #bitcoin ETF looks set to debut Tue...      1\n",
              "2      Top10 Twitter KOL & Gem Rating Oct.18\\n1 $DOGE...      1\n",
              "3         #bitcoin over $62,000 again. \\n\\n$3,000 to go.      1\n",
              "4      Shiba Inu could Reach 50 Cents By December 202...      1\n",
              "...                                                  ...    ...\n",
              "63313  \"\\n@IconicExpert\\n: @nomaxpi \\n@CryptoCobain\\n...      0\n",
              "63314  Can someone send me their btc address? Theblon...      0\n",
              "63315  \"\\n@moolah_io\\n: @GambitBTC $VIA is on the fin...      0\n",
              "63316  What if we all take out loans + buy bitcoin. D...      0\n",
              "63317  Funny indicator for types of people in crypto:...      0\n",
              "\n",
              "[63318 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uw9mu3BiCE63"
      },
      "source": [
        "Vectorizing the "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUErCv_VE8yQ"
      },
      "source": [
        "# Base Line definition\n",
        "\n",
        "Base line accuracy: 56.475%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eq7b3iufGJuF"
      },
      "source": [
        "Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPXgd6qkJM0C",
        "outputId": "2b48258b-7c10-411c-aa9e-a30f71083292"
      },
      "source": [
        "df_tweets_raise['Tweet'] = df_tweets_raise['Tweet'].values.astype('U')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQ3syQyGFIhW"
      },
      "source": [
        "tweets = df_tweets_raise['Tweet'].values\n",
        "y = df_tweets_raise['Raise'].values\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    tweets, \n",
        "    y, \n",
        "    test_size=0.25, \n",
        "    random_state=1000\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4DBexS1G-n-"
      },
      "source": [
        "Creating vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NX3TSmE3HBpt",
        "outputId": "5c882571-0056-4f9e-e82f-4c340229c3d2"
      },
      "source": [
        "vectorizer = CountVectorizer(min_df=0, lowercase=False)\n",
        "vectorizer.fit(df_tweets_raise['Tweet'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "CountVectorizer(lowercase=False, min_df=0)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4V3Ht9PeKQ0r"
      },
      "source": [
        "Vectorizing the train and the test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXiiSC13GRWM",
        "outputId": "fe20f083-8da5-491a-d152-929a939b1a61"
      },
      "source": [
        "vectorizer = CountVectorizer()\n",
        "vectorizer.fit(x_train)\n",
        "\n",
        "X_train = vectorizer.transform(x_train)\n",
        "X_test  = vectorizer.transform(x_test)\n",
        "X_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<47488x35311 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 800964 stored elements in Compressed Sparse Row format>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6U_S7Y4oLNUD"
      },
      "source": [
        "## Logistic Regression\n",
        "Accuracy: 56.475%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "neqGGcP9G8oD",
        "outputId": "e705cc0a-8544-4783-dab4-79e269db79e8"
      },
      "source": [
        "classifier = LogisticRegression()\n",
        "classifier.fit(X_train, y_train)\n",
        "score = classifier.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0D-kL4nKfwF",
        "outputId": "fb8c6cbf-8425-4a5a-8cec-49ab6f49c37a"
      },
      "source": [
        "print(\"Accuracy: \" + '{:.3f}'.format(score*100) + \"%\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 56.469%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hu524oMxLQ1z"
      },
      "source": [
        "# Keras Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gL2jzd83zpq1"
      },
      "source": [
        "## Sequencial Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIOmhqVA_ZHi"
      },
      "source": [
        "### Sequencial Model with tweets column\n",
        "- Testing Accuracy - Test Size 0.25:  56.1213\n",
        "-  Testing Accuracy - Test Size 0.5:  55.5292\n",
        "- Testing Accuracy - 50 epochs: 54.8375\n",
        "- Testing Accuracy - 200 epochs: 55.5198  \n",
        "- Testing Accuracy - Batch size 64: 55.7914\n",
        "- Testing Accuracy - Batch size 128:  -> 56.0157 <-\n",
        "- Testing Accuracy - Batch size 256:  56.0125\n",
        "- Testing Accuracy - Batch size 512:   55.8704\n",
        "- Testing Accuracy - 100 Epochs and Batch size 128: 55.6651"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0wQHas9bV01"
      },
      "source": [
        "#### Test size 0.25"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCzRO872Cz0_"
      },
      "source": [
        "tweets = df_tweets_raise['Tweet'].values\n",
        "y = df_tweets_raise['Raise'].values\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    tweets, \n",
        "    y, \n",
        "    test_size=0.25, \n",
        "    random_state=1000\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilwK8RANC5Sw"
      },
      "source": [
        "vectorizer = CountVectorizer()\n",
        "vectorizer.fit(x_train)\n",
        "\n",
        "X_train = vectorizer.transform(x_train)\n",
        "X_test  = vectorizer.transform(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cduFZ_AjKpbv"
      },
      "source": [
        "input_dim = X_train.shape[1]  # Number of features\n",
        "model = Sequential()\n",
        "model.add(layers.Dense(10, input_dim=input_dim, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POYv6HX-a8W0",
        "outputId": "79dfe4d9-d7b0-4ca9-dd7a-ca4ec68a6893"
      },
      "source": [
        "model.compile(loss='binary_crossentropy', \n",
        "              optimizer='adam', \n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_2 (Dense)             (None, 10)                353120    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 353,131\n",
            "Trainable params: 353,131\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ar2D8T8bI1U",
        "outputId": "0d031fd8-e572-484a-b6ed-263fe32c008b"
      },
      "source": [
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=100,\n",
        "                    verbose=False,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    batch_size=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_1/dense_2/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_1/dense_2/embedding_lookup_sparse/Reshape:0\", shape=(None, 10), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_1/dense_2/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0QsgiaPzRRE",
        "outputId": "ee0a1795-71a1-46ac-9a7a-51f170273416"
      },
      "source": [
        "loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
        "print(\"Training Accuracy: {:.4f}\".format(accuracy*100))\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(accuracy*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Accuracy: 92.7329\n",
            "Testing Accuracy:  56.1213\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSFA-oYpa9oq"
      },
      "source": [
        "#### Test size 0.5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIi7ghS0bHev",
        "outputId": "feee61f4-3fad-4539-a72f-7c11744a3288"
      },
      "source": [
        "tweets = df_nlp_tweets['Tweet'].astype(str).values\n",
        "y = df_nlp_tweets['Raise'].values\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    tweets, \n",
        "    y, \n",
        "    test_size=0.5, \n",
        "    random_state=1000\n",
        "    )\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "vectorizer.fit(x_train)\n",
        "\n",
        "X_train = vectorizer.transform(x_train)\n",
        "X_test  = vectorizer.transform(x_test)\n",
        "input_dim = X_train.shape[1]  # Number of features\n",
        "model = Sequential()\n",
        "model.add(layers.Dense(10, input_dim=input_dim, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', \n",
        "              optimizer='adam', \n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_24 (Dense)            (None, 10)                290800    \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 290,811\n",
            "Trainable params: 290,811\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9q5uta7ObSSP",
        "outputId": "21dad3c1-8fa3-47b5-f510-99d006310f09"
      },
      "source": [
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=100,\n",
        "                    verbose=False,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    batch_size=10)\n",
        "loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
        "print(\"Training Accuracy: {:.4f}\".format(accuracy*100))\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(accuracy*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_12/dense_24/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_12/dense_24/embedding_lookup_sparse/Reshape:0\", shape=(None, 10), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_12/dense_24/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Accuracy: 93.9796\n",
            "Testing Accuracy:  55.5292\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qlWG_4UhSMk4"
      },
      "source": [
        "#### 50 Epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBHvXFCISMk4",
        "outputId": "12b80ed9-18ab-4158-8c3b-7421e8d1f6cd"
      },
      "source": [
        "tweets = df_nlp_tweets['Tweet'].astype(str).values\n",
        "y = df_nlp_tweets['Raise'].values\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    tweets, \n",
        "    y, \n",
        "    test_size=0.5, \n",
        "    random_state=1000\n",
        "    )\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "vectorizer.fit(x_train)\n",
        "\n",
        "X_train = vectorizer.transform(x_train)\n",
        "X_test  = vectorizer.transform(x_test)\n",
        "input_dim = X_train.shape[1]  # Number of features\n",
        "model = Sequential()\n",
        "model.add(layers.Dense(10, input_dim=input_dim, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', \n",
        "              optimizer='adam', \n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_6 (Dense)             (None, 10)                290800    \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 290,811\n",
            "Trainable params: 290,811\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FACTQaUKSMk5",
        "outputId": "fc7a6cc4-24a1-4fe6-8b1f-f741f57ddaec"
      },
      "source": [
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=50,\n",
        "                    verbose=False,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    batch_size=10)\n",
        "loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
        "print(\"Training Accuracy: {:.4f}\".format(accuracy*100))\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(accuracy*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_3/dense_6/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_3/dense_6/embedding_lookup_sparse/Reshape:0\", shape=(None, 10), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_3/dense_6/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Accuracy: 92.7319\n",
            "Testing Accuracy:  54.8375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgtHgcMihfn8"
      },
      "source": [
        "#### 200 Epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AwejpKpehfn9",
        "outputId": "3a6c1d88-0e96-4ace-843a-e077e5537928"
      },
      "source": [
        "tweets = df_nlp_tweets['Tweet'].astype(str).values\n",
        "y = df_nlp_tweets['Raise'].values\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    tweets, \n",
        "    y, \n",
        "    test_size=0.5, \n",
        "    random_state=1000\n",
        "    )\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "vectorizer.fit(x_train)\n",
        "\n",
        "X_train = vectorizer.transform(x_train)\n",
        "X_test  = vectorizer.transform(x_test)\n",
        "input_dim = X_train.shape[1]  # Number of features\n",
        "model = Sequential()\n",
        "model.add(layers.Dense(10, input_dim=input_dim, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', \n",
        "              optimizer='adam', \n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_8 (Dense)             (None, 10)                290800    \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 290,811\n",
            "Trainable params: 290,811\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2kXVq8Chfn-",
        "outputId": "d5d41c7b-1246-4191-ad1d-0a5253f993b8"
      },
      "source": [
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=200,\n",
        "                    verbose=False,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    batch_size=10)\n",
        "loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
        "print(\"Training Accuracy: {:.4f}\".format(accuracy*100))\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(accuracy*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_4/dense_8/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_4/dense_8/embedding_lookup_sparse/Reshape:0\", shape=(None, 10), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_4/dense_8/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Accuracy: 93.6195\n",
            "Testing Accuracy:  55.5198\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsxjz6XIq9Ck"
      },
      "source": [
        "#### Batch size 64"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8QtbVgqq9Cl",
        "outputId": "41582fc0-c4cc-497a-bfe9-0e37a0b5d682"
      },
      "source": [
        "tweets = df_nlp_tweets['Tweet'].astype(str).values\n",
        "y = df_nlp_tweets['Raise'].values\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    tweets, \n",
        "    y, \n",
        "    test_size=0.5, \n",
        "    random_state=1000\n",
        "    )\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "vectorizer.fit(x_train)\n",
        "\n",
        "X_train = vectorizer.transform(x_train)\n",
        "X_test  = vectorizer.transform(x_test)\n",
        "input_dim = X_train.shape[1]  # Number of features\n",
        "model = Sequential()\n",
        "model.add(layers.Dense(10, input_dim=input_dim, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', \n",
        "              optimizer='adam', \n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_10 (Dense)            (None, 10)                290800    \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 290,811\n",
            "Trainable params: 290,811\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPRTOW9jq9Cm",
        "outputId": "e4f1a0b8-63dc-4e0a-817d-d5d1281f627a"
      },
      "source": [
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=100,\n",
        "                    verbose=False,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    batch_size=64)\n",
        "loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
        "print(\"Training Accuracy: {:.4f}\".format(accuracy*100))\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(accuracy*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_5/dense_10/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_5/dense_10/embedding_lookup_sparse/Reshape:0\", shape=(None, 10), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_5/dense_10/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Accuracy: 94.4976\n",
            "Testing Accuracy:  55.7914\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjAFPFU6rZfv"
      },
      "source": [
        "#### Batch size 128"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VfRzuHParZfx",
        "outputId": "08f5c2bc-df48-4268-f1e5-2d114d8fe1b8"
      },
      "source": [
        "tweets = df_nlp_tweets['Tweet'].astype(str).values\n",
        "y = df_nlp_tweets['Raise'].values\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    tweets, \n",
        "    y, \n",
        "    test_size=0.5, \n",
        "    random_state=1000\n",
        "    )\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "vectorizer.fit(x_train)\n",
        "\n",
        "X_train = vectorizer.transform(x_train)\n",
        "X_test  = vectorizer.transform(x_test)\n",
        "input_dim = X_train.shape[1]  # Number of features\n",
        "model = Sequential()\n",
        "model.add(layers.Dense(10, input_dim=input_dim, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', \n",
        "              optimizer='adam', \n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_12 (Dense)            (None, 10)                290800    \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 290,811\n",
            "Trainable params: 290,811\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FfTf0rb7rZfy",
        "outputId": "096c1edf-0628-45ba-f763-e17d9d11b22e"
      },
      "source": [
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=100,\n",
        "                    verbose=False,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    batch_size=128)\n",
        "loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
        "print(\"Training Accuracy: {:.4f}\".format(accuracy*100))\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(accuracy*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_6/dense_12/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_6/dense_12/embedding_lookup_sparse/Reshape:0\", shape=(None, 10), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_6/dense_12/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Accuracy: 94.3555\n",
            "Testing Accuracy:  56.0157\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ar9LtqxNrfE3"
      },
      "source": [
        "#### Batch size 256"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "moNYsregrfE4",
        "outputId": "e4a49eb8-a9ff-4b37-ef35-f42a91adad1d"
      },
      "source": [
        "tweets = df_nlp_tweets['Tweet'].astype(str).values\n",
        "y = df_nlp_tweets['Raise'].values\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    tweets, \n",
        "    y, \n",
        "    test_size=0.5, \n",
        "    random_state=1000\n",
        "    )\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "vectorizer.fit(x_train)\n",
        "\n",
        "X_train = vectorizer.transform(x_train)\n",
        "X_test  = vectorizer.transform(x_test)\n",
        "input_dim = X_train.shape[1]  # Number of features\n",
        "model = Sequential()\n",
        "model.add(layers.Dense(10, input_dim=input_dim, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', \n",
        "              optimizer='adam', \n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_14 (Dense)            (None, 10)                290800    \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 290,811\n",
            "Trainable params: 290,811\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AH3sasmZrfE5",
        "outputId": "04751f45-6ac1-40c9-af89-adcb8e2974e4"
      },
      "source": [
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=100,\n",
        "                    verbose=False,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    batch_size=256)\n",
        "loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
        "print(\"Training Accuracy: {:.4f}\".format(accuracy*100))\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(accuracy*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_7/dense_14/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_7/dense_14/embedding_lookup_sparse/Reshape:0\", shape=(None, 10), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_7/dense_14/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Accuracy: 94.1123\n",
            "Testing Accuracy:  56.0125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0X8EOh3TrjdT"
      },
      "source": [
        "#### Batch size 512"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_H0RJ0urjdT",
        "outputId": "d8f7ceb6-187e-438b-f939-57a9b0cef429"
      },
      "source": [
        "tweets = df_nlp_tweets['Tweet'].astype(str).values\n",
        "y = df_nlp_tweets['Raise'].values\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    tweets, \n",
        "    y, \n",
        "    test_size=0.5, \n",
        "    random_state=1000\n",
        "    )\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "vectorizer.fit(x_train)\n",
        "\n",
        "X_train = vectorizer.transform(x_train)\n",
        "X_test  = vectorizer.transform(x_test)\n",
        "input_dim = X_train.shape[1]  # Number of features\n",
        "model = Sequential()\n",
        "model.add(layers.Dense(10, input_dim=input_dim, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', \n",
        "              optimizer='adam', \n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_16 (Dense)            (None, 10)                290800    \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 290,811\n",
            "Trainable params: 290,811\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CauuYKTcrjdU",
        "outputId": "837c3cdc-357f-440d-d417-20c4c02b80a6"
      },
      "source": [
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=100,\n",
        "                    verbose=False,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    batch_size=128)\n",
        "loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
        "print(\"Training Accuracy: {:.4f}\".format(accuracy*100))\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(accuracy*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_8/dense_16/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_8/dense_16/embedding_lookup_sparse/Reshape:0\", shape=(None, 10), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_8/dense_16/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Accuracy: 94.2955\n",
            "Testing Accuracy:  55.8704\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__5_idHvxUia"
      },
      "source": [
        "#### Epochs = 100 and batch_size = 128"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vu1Chqc9xUib",
        "outputId": "ef4934ca-4b26-4471-cbe2-5d5abd0ab041"
      },
      "source": [
        "tweets = df_nlp_tweets['Tweet'].astype(str).values\n",
        "y = df_nlp_tweets['Raise'].values\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    tweets, \n",
        "    y, \n",
        "    test_size=0.5, \n",
        "    random_state=1000\n",
        "    )\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "vectorizer.fit(x_train)\n",
        "\n",
        "X_train = vectorizer.transform(x_train)\n",
        "X_test  = vectorizer.transform(x_test)\n",
        "input_dim = X_train.shape[1]  # Number of features\n",
        "model = Sequential()\n",
        "model.add(layers.Dense(10, input_dim=input_dim, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', \n",
        "              optimizer='adam', \n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_18 (Dense)            (None, 10)                290800    \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 290,811\n",
            "Trainable params: 290,811\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0n7lTpAxUic",
        "outputId": "90143dcd-7253-48a4-d201-e608461af098"
      },
      "source": [
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=100,\n",
        "                    verbose=False,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    batch_size=512)\n",
        "loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
        "print(\"Training Accuracy: {:.4f}\".format(accuracy*100))\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(accuracy*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_9/dense_18/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_9/dense_18/embedding_lookup_sparse/Reshape:0\", shape=(None, 10), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_9/dense_18/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Accuracy: 93.3321\n",
            "Testing Accuracy:  55.6651\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rnb72o5Ldbb"
      },
      "source": [
        "### Sequencial Model with Data_processing_1 column\n",
        "- Testing Accuracy - Test size 0.25: 56.4940\n",
        "- Testing Accuracy - Test size 0.5: 55.8956\n",
        "- Testing Accuracy - 50 epochs:  56.2224\n",
        "- Testing Accuracy - 200 epochs:  56.2160 \n",
        "- Testing Accuracy - Batch size 64:  56.7214\n",
        "- Testing Accuracy - Batch size 128:  56.8604\n",
        "- Testing Accuracy - Batch size 256:  56.8351\n",
        "- Testing Accuracy - Batch size 512: -> 56.8730 <-\n",
        "- Testing Accuracy - 200 Epochs and Batch size 512: 56.7783"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzKlT6B0HxKJ"
      },
      "source": [
        "#### Test size to 0.25\n",
        "Testing Accuracy:  56.4940"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2xU1swRLmPT"
      },
      "source": [
        "tweets = df_nlp_tweets['Data_processing_1'].astype(str).values\n",
        "y = df_nlp_tweets['Raise'].values\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    tweets, \n",
        "    y, \n",
        "    test_size=0.25, \n",
        "    random_state=1000\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3WmNonNLpaa"
      },
      "source": [
        "vectorizer = CountVectorizer()\n",
        "vectorizer.fit(x_train)\n",
        "\n",
        "X_train = vectorizer.transform(x_train)\n",
        "X_test  = vectorizer.transform(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XN_1exXyOm2s"
      },
      "source": [
        "input_dim = X_train.shape[1]  # Number of features\n",
        "model = Sequential()\n",
        "model.add(layers.Dense(10, input_dim=input_dim, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8g4of5GnOpri",
        "outputId": "eb750db1-8fd8-4147-f359-b75e25ec6f02"
      },
      "source": [
        "model.compile(loss='binary_crossentropy', \n",
        "              optimizer='adam', \n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_2 (Dense)             (None, 10)                353100    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 353,111\n",
            "Trainable params: 353,111\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwm42cd1Othy",
        "outputId": "c3cbdcc1-8509-466b-c427-c4aa8624ac71"
      },
      "source": [
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=100,\n",
        "                    verbose=False,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    batch_size=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_1/dense_2/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_1/dense_2/embedding_lookup_sparse/Reshape:0\", shape=(None, 10), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_1/dense_2/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1IeNSyAOzbE",
        "outputId": "f92f5994-a0e2-464f-dff0-abccdf821103"
      },
      "source": [
        "loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
        "print(\"Training Accuracy: {:.4f}\".format(accuracy*100))\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(accuracy*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Accuracy: 93.4615\n",
            "Testing Accuracy:  56.4940\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_4pKW3QH1NA"
      },
      "source": [
        "#### Test size to 0.5\n",
        "Testing Accuracy:  55.8956"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lq3pWZOMHFHU",
        "outputId": "ab9c9ba5-c758-4600-f448-b94ee962b35a"
      },
      "source": [
        "tweets = df_nlp_tweets['Data_processing_1'].astype(str).values\n",
        "y = df_nlp_tweets['Raise'].values\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    tweets, \n",
        "    y, \n",
        "    test_size=0.5, \n",
        "    random_state=1000\n",
        "    )\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "vectorizer.fit(x_train)\n",
        "\n",
        "X_train = vectorizer.transform(x_train)\n",
        "X_test  = vectorizer.transform(x_test)\n",
        "input_dim = X_train.shape[1]  # Number of features\n",
        "model = Sequential()\n",
        "model.add(layers.Dense(10, input_dim=input_dim, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', \n",
        "              optimizer='adam', \n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_4 (Dense)             (None, 10)                290790    \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 290,801\n",
            "Trainable params: 290,801\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yB56iekPIFBR",
        "outputId": "721af64a-322a-4584-9195-270ad13adba3"
      },
      "source": [
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=100,\n",
        "                    verbose=False,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    batch_size=10)\n",
        "loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
        "print(\"Training Accuracy: {:.4f}\".format(accuracy*100))\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(accuracy*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_2/dense_4/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_2/dense_4/embedding_lookup_sparse/Reshape:0\", shape=(None, 10), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_2/dense_4/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Accuracy: 93.5342\n",
            "Testing Accuracy:  55.8956\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Q0pMsK8RAaJ"
      },
      "source": [
        "#### 50 Epochs\n",
        "Testing Accuracy: 56.2224"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXVPDBJ7RAaS",
        "outputId": "c25dd752-62d1-403a-d1ce-cc7367e026bb"
      },
      "source": [
        "tweets = df_nlp_tweets['Data_processing_1'].astype(str).values\n",
        "y = df_nlp_tweets['Raise'].values\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    tweets, \n",
        "    y, \n",
        "    test_size=0.25, \n",
        "    random_state=1000\n",
        "    )\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "vectorizer.fit(x_train)\n",
        "\n",
        "X_train = vectorizer.transform(x_train)\n",
        "X_test  = vectorizer.transform(x_test)\n",
        "input_dim = X_train.shape[1]  # Number of features\n",
        "model = Sequential()\n",
        "model.add(layers.Dense(10, input_dim=input_dim, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', \n",
        "              optimizer='adam', \n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_22 (Dense)            (None, 10)                353100    \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 353,111\n",
            "Trainable params: 353,111\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dM1xvy3jRAaT",
        "outputId": "bc0ae093-2b54-4a4c-e8c2-ef9897728db3"
      },
      "source": [
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=50,\n",
        "                    verbose=False,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    batch_size=10)\n",
        "loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
        "print(\"Training Accuracy: {:.4f}\".format(accuracy*100))\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(accuracy*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Accuracy: 92.4844\n",
            "Testing Accuracy:  56.2224\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rls6J5OgFkJC"
      },
      "source": [
        "#### 100 Epochs\n",
        "Testing Accuracy: 55.6475"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qktkdPyFkJD",
        "outputId": "e5eefb95-07f0-419e-b71c-bbadd5e0b0d1"
      },
      "source": [
        "tweets = df_nlp_tweets['Data_processing_1'].astype(str).values\n",
        "y = df_nlp_tweets['Raise'].values\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    tweets, \n",
        "    y, \n",
        "    test_size=0.25, \n",
        "    random_state=1000\n",
        "    )\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "vectorizer.fit(x_train)\n",
        "\n",
        "X_train = vectorizer.transform(x_train)\n",
        "X_test  = vectorizer.transform(x_test)\n",
        "input_dim = X_train.shape[1]  # Number of features\n",
        "model = Sequential()\n",
        "model.add(layers.Dense(10, input_dim=input_dim, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', \n",
        "              optimizer='adam', \n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_2 (Dense)             (None, 10)                353100    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 353,111\n",
            "Trainable params: 353,111\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sA6I-Bs5FkJD",
        "outputId": "206d3e05-3d4c-4f9c-a8a2-1e8530418b3a"
      },
      "source": [
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=100,\n",
        "                    verbose=False,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    batch_size=10)\n",
        "loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
        "print(\"Training Accuracy: {:.4f}\".format(accuracy*100))\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(accuracy*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_1/dense_2/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_1/dense_2/embedding_lookup_sparse/Reshape:0\", shape=(None, 10), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_1/dense_2/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Accuracy: 92.8614\n",
            "Testing Accuracy:  55.6475\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "my_Dy333mpQO"
      },
      "source": [
        "#### 200 Epochs\n",
        "Testing Accuracy:  56.2160"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "it2Y962PmpQV",
        "outputId": "a4634ac1-943a-401b-b710-7b0e3b875fe2"
      },
      "source": [
        "tweets = df_nlp_tweets['Data_processing_1'].astype(str).values\n",
        "y = df_nlp_tweets['Raise'].values\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    tweets, \n",
        "    y, \n",
        "    test_size=0.25, \n",
        "    random_state=1000\n",
        "    )\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "vectorizer.fit(x_train)\n",
        "\n",
        "X_train = vectorizer.transform(x_train)\n",
        "X_test  = vectorizer.transform(x_test)\n",
        "input_dim = X_train.shape[1]  # Number of features\n",
        "model = Sequential()\n",
        "model.add(layers.Dense(10, input_dim=input_dim, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', \n",
        "              optimizer='adam', \n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_2 (Dense)             (None, 10)                353100    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 353,111\n",
            "Trainable params: 353,111\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Cw6yDZVmpQV",
        "outputId": "7c197045-8ff0-4d58-92bf-4e5fe3faf707"
      },
      "source": [
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=200,\n",
        "                    verbose=False,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    batch_size=10)\n",
        "loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
        "print(\"Training Accuracy: {:.4f}\".format(accuracy*100))\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(accuracy*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_1/dense_2/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_1/dense_2/embedding_lookup_sparse/Reshape:0\", shape=(None, 10), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_1/dense_2/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Accuracy: 93.4236\n",
            "Testing Accuracy:  56.2160\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVwFwi-4tWSA"
      },
      "source": [
        "#### 64 batch_size\n",
        "Testing Accuracy:  56.7214\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NiY1WxemtWSG",
        "outputId": "4849eea5-a97e-4dd3-834a-fc611d1fa961"
      },
      "source": [
        "tweets = df_nlp_tweets['Data_processing_1'].astype(str).values\n",
        "y = df_nlp_tweets['Raise'].values\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    tweets, \n",
        "    y, \n",
        "    test_size=0.25, \n",
        "    random_state=1000\n",
        "    )\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "vectorizer.fit(x_train)\n",
        "\n",
        "X_train = vectorizer.transform(x_train)\n",
        "X_test  = vectorizer.transform(x_test)\n",
        "input_dim = X_train.shape[1]  # Number of features\n",
        "model = Sequential()\n",
        "model.add(layers.Dense(10, input_dim=input_dim, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', \n",
        "              optimizer='adam', \n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_2 (Dense)             (None, 10)                353100    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 353,111\n",
            "Trainable params: 353,111\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yijHVVo5tWSG",
        "outputId": "57658abe-d6c8-4b4e-c6cf-32ebd6f40c42"
      },
      "source": [
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=10,\n",
        "                    verbose=False,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    batch_size = 64)\n",
        "loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
        "print(\"Training Accuracy: {:.4f}\".format(accuracy*100))\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(accuracy*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Accuracy: 90.4944\n",
            "Testing Accuracy:  56.7214\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11JsbFQ1N_G0"
      },
      "source": [
        "#### 128 batch_size\n",
        "Testing Accuracy: 56.8604\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CS4ILNgLN_G9",
        "outputId": "59039af4-febb-44a2-d7be-564078026e44"
      },
      "source": [
        "tweets = df_nlp_tweets['Data_processing_1'].astype(str).values\n",
        "y = df_nlp_tweets['Raise'].values\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    tweets, \n",
        "    y, \n",
        "    test_size=0.25, \n",
        "    random_state=1000\n",
        "    )\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "vectorizer.fit(x_train)\n",
        "\n",
        "X_train = vectorizer.transform(x_train)\n",
        "X_test  = vectorizer.transform(x_test)\n",
        "input_dim = X_train.shape[1]  # Number of features\n",
        "model = Sequential()\n",
        "model.add(layers.Dense(10, input_dim=input_dim, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', \n",
        "              optimizer='adam', \n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_4 (Dense)             (None, 10)                353100    \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 353,111\n",
            "Trainable params: 353,111\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Tu6FnqTN_G_",
        "outputId": "4d54cf75-80dc-48e4-c4dd-e90786a85265"
      },
      "source": [
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=10,\n",
        "                    verbose=False,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    batch_size = 128)\n",
        "loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
        "print(\"Training Accuracy: {:.4f}\".format(accuracy*100))\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(accuracy*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_2/dense_4/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_2/dense_4/embedding_lookup_sparse/Reshape:0\", shape=(None, 10), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_2/dense_4/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Accuracy: 88.5529\n",
            "Testing Accuracy:  56.8604\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGD19A_xOVfJ"
      },
      "source": [
        "#### 256 batch_size\n",
        "Testing Accuracy: 56.8351\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hJ32xGiOVfK",
        "outputId": "664b4700-259b-4204-cdca-91f9e3d8bfaa"
      },
      "source": [
        "tweets = df_nlp_tweets['Data_processing_1'].astype(str).values\n",
        "y = df_nlp_tweets['Raise'].values\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    tweets, \n",
        "    y, \n",
        "    test_size=0.25, \n",
        "    random_state=1000\n",
        "    )\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "vectorizer.fit(x_train)\n",
        "\n",
        "X_train = vectorizer.transform(x_train)\n",
        "X_test  = vectorizer.transform(x_test)\n",
        "input_dim = X_train.shape[1]  # Number of features\n",
        "model = Sequential()\n",
        "model.add(layers.Dense(10, input_dim=input_dim, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', \n",
        "              optimizer='adam', \n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_6 (Dense)             (None, 10)                353100    \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 353,111\n",
            "Trainable params: 353,111\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tz-quBIlOVfL",
        "outputId": "e57f93c4-ef48-4f7b-aaae-3bbd65764d65"
      },
      "source": [
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=10,\n",
        "                    verbose=False,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    batch_size = 256)\n",
        "loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
        "print(\"Training Accuracy: {:.4f}\".format(accuracy*100))\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(accuracy*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Accuracy: 89.5658\n",
            "Testing Accuracy:  56.8351\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXQrCxksOwLB"
      },
      "source": [
        "#### 512 batch_size\n",
        "Testing Accuracy:  56.8730\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQeP1HGXOwLC",
        "outputId": "60b2ebb1-9e2c-44bb-bf1d-2c3e553f4c8a"
      },
      "source": [
        "tweets = df_nlp_tweets['Data_processing_1'].astype(str).values\n",
        "y = df_nlp_tweets['Raise'].values\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    tweets, \n",
        "    y, \n",
        "    test_size=0.25, \n",
        "    random_state=1000\n",
        "    )\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "vectorizer.fit(x_train)\n",
        "\n",
        "X_train = vectorizer.transform(x_train)\n",
        "X_test  = vectorizer.transform(x_test)\n",
        "input_dim = X_train.shape[1]  # Number of features\n",
        "model = Sequential()\n",
        "model.add(layers.Dense(10, input_dim=input_dim, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', \n",
        "              optimizer='adam', \n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_8 (Dense)             (None, 10)                353100    \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 353,111\n",
            "Trainable params: 353,111\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFnGtWA5OwLC",
        "outputId": "feecf43d-f474-4678-8d69-2a76717dfd13"
      },
      "source": [
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=10,\n",
        "                    verbose=False,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    batch_size = 512)\n",
        "loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
        "print(\"Training Accuracy: {:.4f}\".format(accuracy*100))\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(accuracy*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_4/dense_8/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_4/dense_8/embedding_lookup_sparse/Reshape:0\", shape=(None, 10), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_4/dense_8/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Accuracy: 82.8588\n",
            "Testing Accuracy:  56.8730\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SoC2ieB2PV34"
      },
      "source": [
        "#### Epochs = 200 and batch_size = 512\n",
        "\n",
        "Testing Accuracy:  \n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gccRqKHTPV34",
        "outputId": "0ed8e77e-7aca-49ec-f608-80f3cf024cdc"
      },
      "source": [
        "tweets = df_nlp_tweets['Data_processing_1'].astype(str).values\n",
        "y = df_nlp_tweets['Raise'].values\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    tweets, \n",
        "    y, \n",
        "    test_size=0.25, \n",
        "    random_state=1000\n",
        "    )\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "vectorizer.fit(x_train)\n",
        "\n",
        "X_train = vectorizer.transform(x_train)\n",
        "X_test  = vectorizer.transform(x_test)\n",
        "input_dim = X_train.shape[1]  # Number of features\n",
        "model = Sequential()\n",
        "model.add(layers.Dense(10, input_dim=input_dim, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', \n",
        "              optimizer='adam', \n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 10)                353100    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 353,111\n",
            "Trainable params: 353,111\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPmRiwthPV35",
        "outputId": "e0376fd6-bb66-4012-88c3-4063649b4758"
      },
      "source": [
        "history = model.fit(X_train, y_train,\n",
        "                    epochs = 200,\n",
        "                    verbose=False,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    batch_size = 512)\n",
        "loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
        "print(\"Training Accuracy: {:.4f}\".format(accuracy*100))\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(accuracy*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential/dense/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential/dense/embedding_lookup_sparse/Reshape:0\", shape=(None, 10), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential/dense/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Accuracy: 92.8129\n",
            "Testing Accuracy:  56.7783\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSqySgEeRXfc"
      },
      "source": [
        "### Sequencial Model with Data_processing_2 column\n",
        "- Testing Accuracy - Test size 0.25: 55.8686\n",
        "- Testing Accuracy - Test size 0.5: 56.1010\n",
        "- Testing Accuracy - 50 epochs: 56.1402\n",
        "- Testing Accuracy - 200 epochs: 56.0771\n",
        "- Testing Accuracy - Batch size 64:  56.8162 \n",
        "- Testing Accuracy - Batch size 128: 56.7088\n",
        "- Testing Accuracy - Batch size 256: 56.5698\n",
        "- Testing Accuracy - Batch size 512: 56.2715\n",
        "- Testing Accuracy - 50 Epochs and Batch size 64: -> 57.0246 <-"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2D5ADb6MIIl"
      },
      "source": [
        "#### Test size 0.25\n",
        "Testing Accuracy:  55.8686"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLVbddiSRavb",
        "outputId": "0da9ef80-6574-419b-b160-135ed58b20cf"
      },
      "source": [
        "tweets = df_nlp_tweets['Data_processing_2'].astype(str).values\n",
        "y = df_nlp_tweets['Raise'].values\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    tweets, \n",
        "    y, \n",
        "    test_size=0.25, \n",
        "    random_state=1000\n",
        "    )\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "vectorizer.fit(x_train)\n",
        "\n",
        "X_train = vectorizer.transform(x_train)\n",
        "X_test  = vectorizer.transform(x_test)\n",
        "input_dim = X_train.shape[1]  # Number of features\n",
        "model = Sequential()\n",
        "model.add(layers.Dense(10, input_dim=input_dim, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', \n",
        "              optimizer='adam', \n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_6 (Dense)             (None, 10)                352840    \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 352,851\n",
            "Trainable params: 352,851\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGzAmrSsRbnK",
        "outputId": "a5178406-682f-4124-9b57-87fa868c8307"
      },
      "source": [
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=100,\n",
        "                    verbose=False,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    batch_size=10)\n",
        "loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
        "print(\"Training Accuracy: {:.4f}\".format(accuracy*100))\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(accuracy*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_3/dense_6/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_3/dense_6/embedding_lookup_sparse/Reshape:0\", shape=(None, 10), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_3/dense_6/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Accuracy: 92.8340\n",
            "Testing Accuracy:  55.8686\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6WzcMbGn4DEH"
      },
      "source": [
        "#### Test size 0.5\n",
        "Testing Accuracy:  56.1010"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vaJS1Wo-4DEI",
        "outputId": "28dbea04-3808-4158-b975-e1d783a99915"
      },
      "source": [
        "tweets = df_nlp_tweets['Data_processing_2'].astype(str).values\n",
        "y = df_nlp_tweets['Raise'].values\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    tweets, \n",
        "    y, \n",
        "    test_size=0.5, \n",
        "    random_state=1000\n",
        "    )\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "vectorizer.fit(x_train)\n",
        "\n",
        "X_train = vectorizer.transform(x_train)\n",
        "X_test  = vectorizer.transform(x_test)\n",
        "input_dim = X_train.shape[1]  # Number of features\n",
        "model = Sequential()\n",
        "model.add(layers.Dense(10, input_dim=input_dim, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', \n",
        "              optimizer='adam', \n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_20 (Dense)            (None, 10)                290550    \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 290,561\n",
            "Trainable params: 290,561\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLwFsr_L4DEJ",
        "outputId": "e2a7ae3a-29bc-4188-f180-7981bb93d4b9"
      },
      "source": [
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=100,\n",
        "                    verbose=False,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    batch_size=10)\n",
        "loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
        "print(\"Training Accuracy: {:.4f}\".format(accuracy*100))\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(accuracy*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_10/dense_20/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_10/dense_20/embedding_lookup_sparse/Reshape:0\", shape=(None, 10), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_10/dense_20/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Accuracy: 93.5437\n",
            "Testing Accuracy:  56.1010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4pVVAJHMJag"
      },
      "source": [
        "#### Epochs 50\n",
        "Testing Accuracy: 55.6019"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIoVLtWfMLZN",
        "outputId": "ec400937-c909-497a-fa41-7cef5678967d"
      },
      "source": [
        "tweets = df_nlp_tweets['Data_processing_2'].astype(str).values\n",
        "y = df_nlp_tweets['Raise'].values\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    tweets, \n",
        "    y, \n",
        "    test_size=0.25, \n",
        "    random_state=1000\n",
        "    )\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "vectorizer.fit(x_train)\n",
        "\n",
        "X_train = vectorizer.transform(x_train)\n",
        "X_test  = vectorizer.transform(x_test)\n",
        "input_dim = X_train.shape[1]  # Number of features\n",
        "model = Sequential()\n",
        "model.add(layers.Dense(10, input_dim=input_dim, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', \n",
        "              optimizer='adam', \n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 10)                352840    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 352,851\n",
            "Trainable params: 352,851\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcM_UwLQMSd0",
        "outputId": "4a1dbc69-9996-4d50-b53a-d514aa01fa94"
      },
      "source": [
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=50,\n",
        "                    verbose=False,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    batch_size=10)\n",
        "loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
        "print(\"Training Accuracy: {:.4f}\".format(accuracy*100))\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(accuracy*100))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential/dense/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential/dense/embedding_lookup_sparse/Reshape:0\", shape=(None, 10), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential/dense/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy: 92.9919\n",
            "Testing Accuracy:  56.1402\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T58MFVCI8kdz"
      },
      "source": [
        "#### Epochs 200\n",
        "Testing Accuracy: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfjzxDQ68kdz",
        "outputId": "db7de3dc-f31e-4d61-93e9-30c95c97af71"
      },
      "source": [
        "tweets = df_nlp_tweets['Data_processing_2'].astype(str).values\n",
        "y = df_nlp_tweets['Raise'].values\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    tweets, \n",
        "    y, \n",
        "    test_size=0.25, \n",
        "    random_state=1000\n",
        "    )\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "vectorizer.fit(x_train)\n",
        "\n",
        "X_train = vectorizer.transform(x_train)\n",
        "X_test  = vectorizer.transform(x_test)\n",
        "input_dim = X_train.shape[1]  # Number of features\n",
        "model = Sequential()\n",
        "model.add(layers.Dense(10, input_dim=input_dim, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', \n",
        "              optimizer='adam', \n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_12 (Dense)            (None, 10)                352840    \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 352,851\n",
            "Trainable params: 352,851\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VlgtciW08kdz",
        "outputId": "94ff70dc-c4d0-42cf-d694-e766983db525"
      },
      "source": [
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=200,\n",
        "                    verbose=False,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    batch_size=10)\n",
        "loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
        "print(\"Training Accuracy: {:.4f}\".format(accuracy*100))\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(accuracy*100))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_6/dense_12/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_6/dense_12/embedding_lookup_sparse/Reshape:0\", shape=(None, 10), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_6/dense_12/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy: 93.1351\n",
            "Testing Accuracy:  56.0771\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zs5tVUSQsZx"
      },
      "source": [
        "#### 64 batch_size\n",
        "Testing Accuracy: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtFUlKJDQsZy",
        "outputId": "5e5e2070-730d-44f3-d862-792411a68b7e"
      },
      "source": [
        "tweets = df_nlp_tweets['Data_processing_2'].astype(str).values\n",
        "y = df_nlp_tweets['Raise'].values\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    tweets, \n",
        "    y, \n",
        "    test_size=0.25, \n",
        "    random_state=1000\n",
        "    )\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "vectorizer.fit(x_train)\n",
        "\n",
        "X_train = vectorizer.transform(x_train)\n",
        "X_test  = vectorizer.transform(x_test)\n",
        "input_dim = X_train.shape[1]  # Number of features\n",
        "model = Sequential()\n",
        "model.add(layers.Dense(10, input_dim=input_dim, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', \n",
        "              optimizer='adam', \n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_14 (Dense)            (None, 10)                352840    \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 352,851\n",
            "Trainable params: 352,851\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImUnv-x3QsZy",
        "outputId": "3e6fc9a4-164e-4edc-e5b1-aaf5c3639989"
      },
      "source": [
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=100,\n",
        "                    verbose=False,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    batch_size=64)\n",
        "loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
        "print(\"Training Accuracy: {:.4f}\".format(accuracy*100))\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(accuracy*100))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_7/dense_14/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_7/dense_14/embedding_lookup_sparse/Reshape:0\", shape=(None, 10), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_7/dense_14/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy: 93.6552\n",
            "Testing Accuracy:  56.8162\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErRfS9lLQ10a"
      },
      "source": [
        "#### 128 batch_size\n",
        "Testing Accuracy: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAdlADleQ10b",
        "outputId": "9d8fb094-478c-489f-9d23-95b86dd7d2c7"
      },
      "source": [
        "tweets = df_nlp_tweets['Data_processing_2'].astype(str).values\n",
        "y = df_nlp_tweets['Raise'].values\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    tweets, \n",
        "    y, \n",
        "    test_size=0.25, \n",
        "    random_state=1000\n",
        "    )\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "vectorizer.fit(x_train)\n",
        "\n",
        "X_train = vectorizer.transform(x_train)\n",
        "X_test  = vectorizer.transform(x_test)\n",
        "input_dim = X_train.shape[1]  # Number of features\n",
        "model = Sequential()\n",
        "model.add(layers.Dense(10, input_dim=input_dim, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', \n",
        "              optimizer='adam', \n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_16 (Dense)            (None, 10)                352840    \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 352,851\n",
            "Trainable params: 352,851\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHTjIzUiQ10b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26e6d1bd-76fe-4924-c904-6b4e2e5c50b0"
      },
      "source": [
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=100,\n",
        "                    verbose=False,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    batch_size=128)\n",
        "loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
        "print(\"Training Accuracy: {:.4f}\".format(accuracy*100))\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(accuracy*100))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_8/dense_16/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_8/dense_16/embedding_lookup_sparse/Reshape:0\", shape=(None, 10), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_8/dense_16/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy: 93.5584\n",
            "Testing Accuracy:  56.7088\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOOCrbNeRDVQ"
      },
      "source": [
        "#### 256 batch_size\n",
        "Testing Accuracy: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jghYUSGyRDVQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf11a3e5-2f5e-46fe-895b-10fad8e7177d"
      },
      "source": [
        "tweets = df_nlp_tweets['Data_processing_2'].astype(str).values\n",
        "y = df_nlp_tweets['Raise'].values\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    tweets, \n",
        "    y, \n",
        "    test_size=0.25, \n",
        "    random_state=1000\n",
        "    )\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "vectorizer.fit(x_train)\n",
        "\n",
        "X_train = vectorizer.transform(x_train)\n",
        "X_test  = vectorizer.transform(x_test)\n",
        "input_dim = X_train.shape[1]  # Number of features\n",
        "model = Sequential()\n",
        "model.add(layers.Dense(10, input_dim=input_dim, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', \n",
        "              optimizer='adam', \n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_18 (Dense)            (None, 10)                352840    \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 352,851\n",
            "Trainable params: 352,851\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvnM5XGKRDVR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "152325bb-3715-4d7f-9952-d2953f8c9ea1"
      },
      "source": [
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=100,\n",
        "                    verbose=False,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    batch_size=256)\n",
        "loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
        "print(\"Training Accuracy: {:.4f}\".format(accuracy*100))\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(accuracy*100))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_9/dense_18/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_9/dense_18/embedding_lookup_sparse/Reshape:0\", shape=(None, 10), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_9/dense_18/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy: 93.2973\n",
            "Testing Accuracy:  56.5698\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZQnAmsBRGxe"
      },
      "source": [
        "#### 512 batch_size\n",
        "Testing Accuracy: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJ0k97FZRGxe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d50a53c0-1757-4fe3-db3b-af1bd2732192"
      },
      "source": [
        "tweets = df_nlp_tweets['Data_processing_2'].astype(str).values\n",
        "y = df_nlp_tweets['Raise'].values\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    tweets, \n",
        "    y, \n",
        "    test_size=0.5, \n",
        "    random_state=1000\n",
        "    )\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "vectorizer.fit(x_train)\n",
        "\n",
        "X_train = vectorizer.transform(x_train)\n",
        "X_test  = vectorizer.transform(x_test)\n",
        "input_dim = X_train.shape[1]  # Number of features\n",
        "model = Sequential()\n",
        "model.add(layers.Dense(10, input_dim=input_dim, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', \n",
        "              optimizer='adam', \n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_20 (Dense)            (None, 10)                290550    \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 290,561\n",
            "Trainable params: 290,561\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0dUJ83URGxe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "559efc23-9e61-436d-b9df-656ab27d7a91"
      },
      "source": [
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=100,\n",
        "                    verbose=False,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    batch_size=512)\n",
        "loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
        "print(\"Training Accuracy: {:.4f}\".format(accuracy*100))\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(accuracy*100))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_10/dense_20/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_10/dense_20/embedding_lookup_sparse/Reshape:0\", shape=(None, 10), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_10/dense_20/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy: 93.2184\n",
            "Testing Accuracy:  56.2715\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdtHJ19aCEW5"
      },
      "source": [
        "#### Epochs 50 and 64 batch_size\n",
        "Testing Accuracy: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQPrjm9UCEW6",
        "outputId": "ecb7f890-5377-4bb7-fd7d-f56b5d1b887e"
      },
      "source": [
        "tweets = df_nlp_tweets['Data_processing_2'].astype(str).values\n",
        "y = df_nlp_tweets['Raise'].values\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    tweets, \n",
        "    y, \n",
        "    test_size=0.25, \n",
        "    random_state=1000\n",
        "    )\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "vectorizer.fit(x_train)\n",
        "\n",
        "X_train = vectorizer.transform(x_train)\n",
        "X_test  = vectorizer.transform(x_test)\n",
        "input_dim = X_train.shape[1]  # Number of features\n",
        "model = Sequential()\n",
        "model.add(layers.Dense(10, input_dim=input_dim, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', \n",
        "              optimizer='adam', \n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_22 (Dense)            (None, 10)                352840    \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 352,851\n",
            "Trainable params: 352,851\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "huw30SwOCEW6",
        "outputId": "98fca36c-2039-40c6-c9dc-5a24ccf45c75"
      },
      "source": [
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=50,\n",
        "                    verbose=False,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    batch_size = 64)\n",
        "loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
        "print(\"Training Accuracy: {:.4f}\".format(accuracy*100))\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(accuracy*100))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_11/dense_22/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_11/dense_22/embedding_lookup_sparse/Reshape:0\", shape=(None, 10), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_11/dense_22/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy: 93.2952\n",
            "Testing Accuracy:  57.0246\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rj3Ibnem5abk"
      },
      "source": [
        "### Sequencial Model with Data_processing_3 column\n",
        "- Testing Accuracy - Test size 0.25: 55.9760\n",
        "- Testing Accuracy - Test size 0.5: 55.9114\n",
        "- Testing Accuracy - 50 epochs: 56.7909\n",
        "- Testing Accuracy - 200 epochs: 55.8433\n",
        "- Testing Accuracy - Batch size 64: 56.9109\n",
        "- Testing Accuracy - Batch size 128: 56.1402\n",
        "- Testing Accuracy - Batch size 256: 56.8225\n",
        "- Testing Accuracy - Batch size 512: 56.5256\n",
        "- Testing Accuracy - 50 Epochs and Batch size 64: 57.1004\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zcYYPuCCFbi"
      },
      "source": [
        "#### Test size 0.25\n",
        "Testing Accuracy:  55.9760"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcOXIZG15abk"
      },
      "source": [
        "tweets = df_nlp_tweets['Data_processing_3'].values\n",
        "y = df_nlp_tweets['Raise'].values\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    tweets, \n",
        "    y, \n",
        "    test_size=0.25, \n",
        "    random_state=1000\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQt_cBkf5abk"
      },
      "source": [
        "vectorizer = CountVectorizer()\n",
        "vectorizer.fit(x_train)\n",
        "\n",
        "X_train = vectorizer.transform(x_train)\n",
        "X_test  = vectorizer.transform(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_T22efFG5abl"
      },
      "source": [
        "input_dim = X_train.shape[1]  # Number of features\n",
        "model = Sequential()\n",
        "model.add(layers.Dense(10, input_dim=input_dim, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQUbYh5O5abl",
        "outputId": "344b1b26-216e-47e3-9025-ed7390872150"
      },
      "source": [
        "model.compile(loss='binary_crossentropy', \n",
        "              optimizer='adam', \n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_4 (Dense)             (None, 10)                351450    \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 351,461\n",
            "Trainable params: 351,461\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-b3LWqTo5abl",
        "outputId": "7b808ee0-0f99-4c27-df93-f09e0d49404b"
      },
      "source": [
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=100,\n",
        "                    verbose=False,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    batch_size=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_2/dense_4/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_2/dense_4/embedding_lookup_sparse/Reshape:0\", shape=(None, 10), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_2/dense_4/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81OODYDQ5abl",
        "outputId": "a8eb6a76-d432-47bb-957d-3b63018aed05"
      },
      "source": [
        "loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
        "print(\"Training Accuracy: {:.4f}\".format(accuracy*100))\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(accuracy*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Accuracy: 92.7161\n",
            "Testing Accuracy:  55.9760\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hqk7Y5gCG5x"
      },
      "source": [
        "#### Test size 0.5\n",
        "Testing Accuracy:  55.9114"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZFD3PqcCPqY",
        "outputId": "a74180e9-3804-4304-a642-d57181deb0a3"
      },
      "source": [
        "tweets = df_nlp_tweets['Data_processing_3'].astype(str).values\n",
        "y = df_nlp_tweets['Raise'].values\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    tweets, \n",
        "    y, \n",
        "    test_size=0.5, \n",
        "    random_state=1000\n",
        "    )\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "vectorizer.fit(x_train)\n",
        "\n",
        "X_train = vectorizer.transform(x_train)\n",
        "X_test  = vectorizer.transform(x_test)\n",
        "input_dim = X_train.shape[1]  # Number of features\n",
        "model = Sequential()\n",
        "model.add(layers.Dense(10, input_dim=input_dim, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', \n",
        "              optimizer='adam', \n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_16 (Dense)            (None, 10)                289160    \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 289,171\n",
            "Trainable params: 289,171\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJoZTOlqCRzw",
        "outputId": "133636d3-fc8e-4808-9c02-a7b404e291c1"
      },
      "source": [
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=100,\n",
        "                    verbose=False,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    batch_size=10)\n",
        "loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
        "print(\"Training Accuracy: {:.4f}\".format(accuracy*100))\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(accuracy*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_8/dense_16/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_8/dense_16/embedding_lookup_sparse/Reshape:0\", shape=(None, 10), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_8/dense_16/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Accuracy: 94.2007\n",
            "Testing Accuracy:  55.9114\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_wApeL7VSUD"
      },
      "source": [
        "#### 50 epochs\n",
        "Testing Accuracy: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2buGrlToVSUE",
        "outputId": "4e95581a-de55-4db2-b9e3-1eaa947b8a23"
      },
      "source": [
        "tweets = df_nlp_tweets['Data_processing_3'].values\n",
        "y = df_nlp_tweets['Raise'].values\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    tweets, \n",
        "    y, \n",
        "    test_size=0.25, \n",
        "    random_state=1000\n",
        "    )\n",
        "vectorizer = CountVectorizer()\n",
        "vectorizer.fit(x_train)\n",
        "\n",
        "X_train = vectorizer.transform(x_train)\n",
        "X_test  = vectorizer.transform(x_test)\n",
        "input_dim = X_train.shape[1]  # Number of features\n",
        "model = Sequential()\n",
        "model.add(layers.Dense(10, input_dim=input_dim, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', \n",
        "              optimizer='adam', \n",
        "              metrics=['accuracy'])\n",
        "model.summary()\n",
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=50,\n",
        "                    verbose=False,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    batch_size=10)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_26 (Dense)            (None, 10)                351450    \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 351,461\n",
            "Trainable params: 351,461\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_13/dense_26/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_13/dense_26/embedding_lookup_sparse/Reshape:0\", shape=(None, 10), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_13/dense_26/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vecCAvRtVSUF",
        "outputId": "97264cc2-e95a-455c-f64f-f962bb99d28c"
      },
      "source": [
        "loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
        "print(\"Training Accuracy: {:.4f}\".format(accuracy*100))\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(accuracy*100))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy: 91.1809\n",
            "Testing Accuracy:  56.7909\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kiVXaOOoVTyE"
      },
      "source": [
        "#### 200 epochs\n",
        "Testing Accuracy: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJasLfgPVTyE",
        "outputId": "45a9837d-720c-4fcd-ae61-269398aebb4f"
      },
      "source": [
        "tweets = df_nlp_tweets['Data_processing_3'].values\n",
        "y = df_nlp_tweets['Raise'].values\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    tweets, \n",
        "    y, \n",
        "    test_size=0.25, \n",
        "    random_state=1000\n",
        "    )\n",
        "vectorizer = CountVectorizer()\n",
        "vectorizer.fit(x_train)\n",
        "\n",
        "X_train = vectorizer.transform(x_train)\n",
        "X_test  = vectorizer.transform(x_test)\n",
        "input_dim = X_train.shape[1]  # Number of features\n",
        "model = Sequential()\n",
        "model.add(layers.Dense(10, input_dim=input_dim, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', \n",
        "              optimizer='adam', \n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_32 (Dense)            (None, 10)                351450    \n",
            "                                                                 \n",
            " dense_33 (Dense)            (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 351,461\n",
            "Trainable params: 351,461\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fgt-tdaRVTyF",
        "outputId": "f6cf05b9-5f2a-49af-a514-60ebdc420270"
      },
      "source": [
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=200,\n",
        "                    verbose=False,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    batch_size=10)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_16/dense_32/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_16/dense_32/embedding_lookup_sparse/Reshape:0\", shape=(None, 10), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_16/dense_32/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHp5N6zBVTyF",
        "outputId": "11be5547-a6dc-45f8-b93a-bd149faaf106"
      },
      "source": [
        "loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
        "print(\"Training Accuracy: {:.4f}\".format(accuracy*100))\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(accuracy*100))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy: 92.2401\n",
            "Testing Accuracy:  55.8433\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uApEvVIvWAgc"
      },
      "source": [
        "#### 64 batch_size\n",
        "Testing Accuracy: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Ve9DRRiWAgc",
        "outputId": "a74f1f61-c8b2-4ab1-a344-0aa0ef5f666e"
      },
      "source": [
        "tweets = df_nlp_tweets['Data_processing_3'].values\n",
        "y = df_nlp_tweets['Raise'].values\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    tweets, \n",
        "    y, \n",
        "    test_size=0.25, \n",
        "    random_state=1000\n",
        "    )\n",
        "vectorizer = CountVectorizer()\n",
        "vectorizer.fit(x_train)\n",
        "\n",
        "X_train = vectorizer.transform(x_train)\n",
        "X_test  = vectorizer.transform(x_test)\n",
        "input_dim = X_train.shape[1]  # Number of features\n",
        "model = Sequential()\n",
        "model.add(layers.Dense(10, input_dim=input_dim, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', \n",
        "              optimizer='adam', \n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_34 (Dense)            (None, 10)                351450    \n",
            "                                                                 \n",
            " dense_35 (Dense)            (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 351,461\n",
            "Trainable params: 351,461\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThJD5BluWAgd",
        "outputId": "29e79c0d-33bc-41ed-fd60-769a995f203b"
      },
      "source": [
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=100,\n",
        "                    verbose=False,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    batch_size=64)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_17/dense_34/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_17/dense_34/embedding_lookup_sparse/Reshape:0\", shape=(None, 10), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_17/dense_34/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCbJEtVfWAgd",
        "outputId": "d2e41bc6-32d6-479c-baaf-a666a105f45c"
      },
      "source": [
        "loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
        "print(\"Training Accuracy: {:.4f}\".format(accuracy*100))\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(accuracy*100))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy: 93.5563\n",
            "Testing Accuracy:  56.9109\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JsAZ2dkWbTE"
      },
      "source": [
        "#### 128 batch_size\n",
        "Testing Accuracy: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cThJSgNdWbTF",
        "outputId": "a4bdda2c-f0e7-412c-f42a-936d9ee691b5"
      },
      "source": [
        "tweets = df_nlp_tweets['Data_processing_3'].values\n",
        "y = df_nlp_tweets['Raise'].values\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    tweets, \n",
        "    y, \n",
        "    test_size=0.25, \n",
        "    random_state=1000\n",
        "    )\n",
        "vectorizer = CountVectorizer()\n",
        "vectorizer.fit(x_train)\n",
        "\n",
        "X_train = vectorizer.transform(x_train)\n",
        "X_test  = vectorizer.transform(x_test)\n",
        "input_dim = X_train.shape[1]  # Number of features\n",
        "model = Sequential()\n",
        "model.add(layers.Dense(10, input_dim=input_dim, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', \n",
        "              optimizer='adam', \n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_18\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_36 (Dense)            (None, 10)                351450    \n",
            "                                                                 \n",
            " dense_37 (Dense)            (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 351,461\n",
            "Trainable params: 351,461\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CoDpi5auWbTG",
        "outputId": "ace3adf9-0b7a-4506-e7f1-59e31fd213d7"
      },
      "source": [
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=100,\n",
        "                    verbose=False,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    batch_size=128)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_18/dense_36/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_18/dense_36/embedding_lookup_sparse/Reshape:0\", shape=(None, 10), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_18/dense_36/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXK7yDo5WbTH",
        "outputId": "3d43d1f7-9140-4a89-d58b-eb1b8c9cd93e"
      },
      "source": [
        "loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
        "print(\"Training Accuracy: {:.4f}\".format(accuracy*100))\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(accuracy*100))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy: 93.1856\n",
            "Testing Accuracy:  56.1402\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDpXvIHvWcVj"
      },
      "source": [
        "#### 256 batch_size\n",
        "Testing Accuracy: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nuF_iJx5WcVj",
        "outputId": "72cda149-d385-43f8-8a73-0e24103d5698"
      },
      "source": [
        "tweets = df_nlp_tweets['Data_processing_3'].values\n",
        "y = df_nlp_tweets['Raise'].values\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    tweets, \n",
        "    y, \n",
        "    test_size=0.25, \n",
        "    random_state=1000\n",
        "    )\n",
        "vectorizer = CountVectorizer()\n",
        "vectorizer.fit(x_train)\n",
        "\n",
        "X_train = vectorizer.transform(x_train)\n",
        "X_test  = vectorizer.transform(x_test)\n",
        "input_dim = X_train.shape[1]  # Number of features\n",
        "model = Sequential()\n",
        "model.add(layers.Dense(10, input_dim=input_dim, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', \n",
        "              optimizer='adam', \n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_19\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_38 (Dense)            (None, 10)                351450    \n",
            "                                                                 \n",
            " dense_39 (Dense)            (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 351,461\n",
            "Trainable params: 351,461\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lR7Qo6bwWcVj",
        "outputId": "8357ea93-b999-43d7-e462-72f18d055f3d"
      },
      "source": [
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=100,\n",
        "                    verbose=False,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    batch_size=256)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_19/dense_38/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_19/dense_38/embedding_lookup_sparse/Reshape:0\", shape=(None, 10), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_19/dense_38/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NeDcNIIqWcVj",
        "outputId": "0eb5b428-3abc-4e8a-abbc-b96a0963afcb"
      },
      "source": [
        "loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
        "print(\"Training Accuracy: {:.4f}\".format(accuracy*100))\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(accuracy*100))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy: 93.0740\n",
            "Testing Accuracy:  56.8225\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5fWnreGWhC4"
      },
      "source": [
        "#### 512 batch_size\n",
        "Testing Accuracy: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQgeC0MVWhC4",
        "outputId": "3847bf88-e6b9-4330-dab6-fb3794793a0b"
      },
      "source": [
        "tweets = df_nlp_tweets['Data_processing_3'].values\n",
        "y = df_nlp_tweets['Raise'].values\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    tweets, \n",
        "    y, \n",
        "    test_size=0.25, \n",
        "    random_state=1000\n",
        "    )\n",
        "vectorizer = CountVectorizer()\n",
        "vectorizer.fit(x_train)\n",
        "\n",
        "X_train = vectorizer.transform(x_train)\n",
        "X_test  = vectorizer.transform(x_test)\n",
        "input_dim = X_train.shape[1]  # Number of features\n",
        "model = Sequential()\n",
        "model.add(layers.Dense(10, input_dim=input_dim, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', \n",
        "              optimizer='adam', \n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_20\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_40 (Dense)            (None, 10)                351450    \n",
            "                                                                 \n",
            " dense_41 (Dense)            (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 351,461\n",
            "Trainable params: 351,461\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUoGWjI_WhC5",
        "outputId": "d4c0b610-17cb-456b-8b68-6c3c2eb0d468"
      },
      "source": [
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=100,\n",
        "                    verbose=False,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    batch_size=512)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_20/dense_40/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_20/dense_40/embedding_lookup_sparse/Reshape:0\", shape=(None, 10), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_20/dense_40/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHKb-eMBWhC5",
        "outputId": "dd145c2f-2aeb-442d-85d4-0d58c4cb9b13"
      },
      "source": [
        "loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
        "print(\"Training Accuracy: {:.4f}\".format(accuracy*100))\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(accuracy*100))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy: 92.5897\n",
            "Testing Accuracy:  56.5256\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Z08Tpa5BH6n"
      },
      "source": [
        "50 Epochs and Batch size 64:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfKyZdzlBTX3"
      },
      "source": [
        "#### 50 Epochs and Batch size 64\n",
        "Testing Accuracy: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Axuei9YRBTX4",
        "outputId": "029a1d93-072f-4531-9b9f-c1eb1da2d45c"
      },
      "source": [
        "tweets = df_nlp_tweets['Data_processing_3'].values\n",
        "y = df_nlp_tweets['Raise'].values\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    tweets, \n",
        "    y, \n",
        "    test_size=0.25, \n",
        "    random_state=1000\n",
        "    )\n",
        "vectorizer = CountVectorizer()\n",
        "vectorizer.fit(x_train)\n",
        "\n",
        "X_train = vectorizer.transform(x_train)\n",
        "X_test  = vectorizer.transform(x_test)\n",
        "input_dim = X_train.shape[1]  # Number of features\n",
        "model = Sequential()\n",
        "model.add(layers.Dense(10, input_dim=input_dim, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', \n",
        "              optimizer='adam', \n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_21\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_42 (Dense)            (None, 10)                351450    \n",
            "                                                                 \n",
            " dense_43 (Dense)            (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 351,461\n",
            "Trainable params: 351,461\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkgOOfIJBTX5",
        "outputId": "a6e77e2d-73aa-4fd5-8572-0706656144bc"
      },
      "source": [
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=50,\n",
        "                    verbose=False,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    batch_size=64)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_21/dense_42/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_21/dense_42/embedding_lookup_sparse/Reshape:0\", shape=(None, 10), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_21/dense_42/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvyf_vLfBTX5",
        "outputId": "da9913e2-97ee-46ad-8c2a-9a56e075a95e"
      },
      "source": [
        "loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
        "print(\"Training Accuracy: {:.4f}\".format(accuracy*100))\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(accuracy*100))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy: 93.4110\n",
            "Testing Accuracy:  57.1004\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVGzRWD9eJhZ"
      },
      "source": [
        "### Sequencial Model with Data_processing_4 column\n",
        "- Testing Accuracy  - Test size 0.25:  55.8686\n",
        "- Testing Accuracy - Test size 0.5: 55.2607"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srs_r1L557W3"
      },
      "source": [
        "#### Test size 0.25\n",
        "Testing Accuracy:  55.0663"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-C92dufeJhg",
        "outputId": "ef79db22-319c-426f-b3d2-240407cf9512"
      },
      "source": [
        "tweets = df_nlp_tweets['Data_processing_4'].astype(str).values\n",
        "y = df_nlp_tweets['Raise'].values\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    tweets, \n",
        "    y, \n",
        "    test_size=0.25, \n",
        "    random_state=1000\n",
        "    )\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "vectorizer.fit(x_train)\n",
        "\n",
        "X_train = vectorizer.transform(x_train)\n",
        "X_test  = vectorizer.transform(x_test)\n",
        "input_dim = X_train.shape[1]  # Number of features\n",
        "model = Sequential()\n",
        "model.add(layers.Dense(10, input_dim=input_dim, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', \n",
        "              optimizer='adam', \n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_8 (Dense)             (None, 10)                261100    \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 261,111\n",
            "Trainable params: 261,111\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvwZJcxgeJhg",
        "outputId": "ae70f866-d6d6-4eb5-bc61-f05f40e39c26"
      },
      "source": [
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=100,\n",
        "                    verbose=False,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    batch_size=10)\n",
        "loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
        "print(\"Training Accuracy: {:.4f}\".format(accuracy*100))\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(accuracy*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_4/dense_8/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_4/dense_8/embedding_lookup_sparse/Reshape:0\", shape=(None, 10), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_4/dense_8/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Accuracy: 90.6692\n",
            "Testing Accuracy:  55.0663\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAkt2f-R58sY"
      },
      "source": [
        "#### Test size 0.5\n",
        "Testing Accuracy:  55.2607"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SACNlJsI5_pB",
        "outputId": "dffbc3f1-bff1-4bb3-8d5f-9a9f288a4402"
      },
      "source": [
        "tweets = df_nlp_tweets['Data_processing_4'].astype(str).values\n",
        "y = df_nlp_tweets['Raise'].values\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    tweets, \n",
        "    y, \n",
        "    test_size=0.5, \n",
        "    random_state=1000\n",
        "    )\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "vectorizer.fit(x_train)\n",
        "\n",
        "X_train = vectorizer.transform(x_train)\n",
        "X_test  = vectorizer.transform(x_test)\n",
        "input_dim = X_train.shape[1]  # Number of features\n",
        "model = Sequential()\n",
        "model.add(layers.Dense(10, input_dim=input_dim, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', \n",
        "              optimizer='adam', \n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_14 (Dense)            (None, 10)                213820    \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 213,831\n",
            "Trainable params: 213,831\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHx1P5mH6Aq3",
        "outputId": "cd750d0f-b264-439c-b35c-baf6cdd22c65"
      },
      "source": [
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=100,\n",
        "                    verbose=False,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    batch_size=10)\n",
        "loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
        "print(\"Training Accuracy: {:.4f}\".format(accuracy*100))\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(accuracy*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_7/dense_14/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_7/dense_14/embedding_lookup_sparse/Reshape:0\", shape=(None, 10), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_7/dense_14/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Accuracy: 93.4237\n",
            "Testing Accuracy:  55.2607\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fqVs3NZejAj"
      },
      "source": [
        "### Sequencial Model with Data_processing_5 column\n",
        "- Testing Accuracy - Test size 0.25:  56.7720\n",
        "- Testing Accuracy - Test size 0.5: 55.6524"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQlsI9S6yqB3"
      },
      "source": [
        "#### Test size 0.25\n",
        "Testing Accuracy:  56.7720"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dG0d-5J0ejAk",
        "outputId": "6971062b-b44a-4c44-e9ec-779e7501da35"
      },
      "source": [
        "tweets = df_nlp_tweets['Data_processing_5'].astype(str).values\n",
        "y = df_nlp_tweets['Raise'].values\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    tweets, \n",
        "    y, \n",
        "    test_size=0.25, \n",
        "    random_state=1000\n",
        "    )\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "vectorizer.fit(x_train)\n",
        "\n",
        "X_train = vectorizer.transform(x_train)\n",
        "X_test  = vectorizer.transform(x_test)\n",
        "input_dim = X_train.shape[1]  # Number of features\n",
        "model = Sequential()\n",
        "model.add(layers.Dense(10, input_dim=input_dim, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', \n",
        "              optimizer='adam', \n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_10 (Dense)            (None, 10)                261050    \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 261,061\n",
            "Trainable params: 261,061\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AEiM1NACejAk",
        "outputId": "91febefe-d638-4e8b-977d-109be79ff30e"
      },
      "source": [
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=100,\n",
        "                    verbose=False,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    batch_size=10)\n",
        "loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
        "print(\"Training Accuracy: {:.4f}\".format(accuracy*100))\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(accuracy*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_5/dense_10/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_5/dense_10/embedding_lookup_sparse/Reshape:0\", shape=(None, 10), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_5/dense_10/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Accuracy: 92.9287\n",
            "Testing Accuracy:  56.7720\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SrF4PktAyvii"
      },
      "source": [
        "#### Test size 0.5\n",
        "Testing Accuracy:  55.6524"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8JdJZV8zyxaG",
        "outputId": "a41a408e-595c-49e3-eb70-51dc92edee10"
      },
      "source": [
        "tweets = df_nlp_tweets['Data_processing_5'].astype(str).values\n",
        "y = df_nlp_tweets['Raise'].values\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    tweets, \n",
        "    y, \n",
        "    test_size=0.50, \n",
        "    random_state=1000\n",
        "    )\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "vectorizer.fit(x_train)\n",
        "\n",
        "X_train = vectorizer.transform(x_train)\n",
        "X_test  = vectorizer.transform(x_test)\n",
        "input_dim = X_train.shape[1]  # Number of features\n",
        "model = Sequential()\n",
        "model.add(layers.Dense(10, input_dim=input_dim, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', \n",
        "              optimizer='adam', \n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_12 (Dense)            (None, 10)                213570    \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 213,581\n",
            "Trainable params: 213,581\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejGQ7qVDyyRn",
        "outputId": "2d595b11-9cbd-4a43-f1ca-dc19aac32603"
      },
      "source": [
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=100,\n",
        "                    verbose=False,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    batch_size=10)\n",
        "loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
        "print(\"Training Accuracy: {:.4f}\".format(accuracy*100))\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(accuracy*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_6/dense_12/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_6/dense_12/embedding_lookup_sparse/Reshape:0\", shape=(None, 10), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_6/dense_12/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Accuracy: 93.0731\n",
            "Testing Accuracy:  55.6524\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wu8xjuBRzs2F"
      },
      "source": [
        "## LabelEncoder and HotEncoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1rdETws8c2j"
      },
      "source": [
        "## Keras Embedding Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgLvwPI50yec"
      },
      "source": [
        "### Word Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imyY95Yim4o4"
      },
      "source": [
        "clear_session()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTgYeVlk7Rot"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    tweets, \n",
        "    y, \n",
        "    test_size=0.15, \n",
        "    random_state=1000\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dg1E6vl2hZln"
      },
      "source": [
        "- alterar parametros do toknizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RT6ePlXO7L90",
        "outputId": "cd28d90d-63c1-49fd-9267-d0672501b555"
      },
      "source": [
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(x_train)\n",
        "\n",
        "X_train = tokenizer.texts_to_sequences(x_train)\n",
        "X_test = tokenizer.texts_to_sequences(x_test)\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1  # Adding 1 because of reserved 0 index\n",
        "\n",
        "print(x_train[2])\n",
        "print(X_train[2])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SpaceX makes it cheaper to launch rockets.\n",
            "\n",
            "Someone will make it cheaper to discover medicine, produce construction materials, & feed humans\n",
            "[2103, 276, 12, 2723, 2, 798, 4943, 180, 21, 67, 12, 2723, 2, 1921, 2309, 1663, 787]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfX9oHfp8Rbt"
      },
      "source": [
        "max_len_tweet = 280\n",
        "\n",
        "X_train = pad_sequences(X_train, padding='post', maxlen=max_len_tweet)\n",
        "X_test = pad_sequences(X_test, padding='post', maxlen=max_len_tweet)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Ns9ArC38gqT"
      },
      "source": [
        "### Sequecial model with Word Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUizJS_X8nS7",
        "outputId": "354c9043-4744-40e9-f842-0717dc7d9178"
      },
      "source": [
        "embedding_dim = 50\n",
        "\n",
        "model = Sequential()\n",
        "model.add(layers.Embedding(input_dim=vocab_size, \n",
        "                           output_dim=embedding_dim, \n",
        "                           input_length=max_len_tweet))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(10, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 280, 50)           2061850   \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 14000)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                140010    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,201,871\n",
            "Trainable params: 2,201,871\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJbl3TkW9QL0",
        "outputId": "00cd3509-76fd-47ea-96ef-0384c670c9d7"
      },
      "source": [
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=20,\n",
        "                    verbose=False,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    batch_size=10)\n",
        "loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
        "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Accuracy: 0.5419\n",
            "Testing Accuracy:  0.5396\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VV-zOLwsKNWG"
      },
      "source": [
        "### Sequecial model with Word Embeddings and GlobalMaxPool1D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWcXCagXxez_"
      },
      "source": [
        "clear_session()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZ6j3hHGx0JP"
      },
      "source": [
        "tweets = df_tweets_raise['Tweet'].values\n",
        "y = df_tweets_raise['Raise'].values\n",
        "encoder = LabelEncoder()\n",
        "tweets_label_encoder = encoder.fit_transform(tweets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XR0kJFmhxnJZ",
        "outputId": "70db75b0-a4cc-45bd-fa56-6d53793f7920"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    tweets, \n",
        "    y, \n",
        "    test_size=0.15, \n",
        "    random_state=1000\n",
        "    )\n",
        "\n",
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(x_train)\n",
        "\n",
        "X_train = tokenizer.texts_to_sequences(x_train)\n",
        "X_test = tokenizer.texts_to_sequences(x_test)\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1  # Adding 1 because of reserved 0 index\n",
        "\n",
        "print(x_train[2])\n",
        "print(X_train[2])\n",
        "\n",
        "\n",
        "\n",
        "max_len_tweet = 280\n",
        "\n",
        "X_train = pad_sequences(X_train, padding='post', maxlen=max_len_tweet)\n",
        "X_test = pad_sequences(X_test, padding='post', maxlen=max_len_tweet)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SpaceX makes it cheaper to launch rockets.\n",
            "\n",
            "Someone will make it cheaper to discover medicine, produce construction materials, & feed humans\n",
            "[2103, 276, 12, 2723, 2, 798, 4943, 180, 21, 67, 12, 2723, 2, 1921, 2309, 1663, 787]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vyBJ7bqVKPuW",
        "outputId": "d2a7ed0c-fe47-4a35-8b77-3d9958df05f1"
      },
      "source": [
        "\n",
        "embedding_dim = 50\n",
        "\n",
        "model = Sequential()\n",
        "model.add(layers.Embedding(input_dim=vocab_size, \n",
        "                           output_dim=embedding_dim, \n",
        "                           input_length=max_len_tweet))\n",
        "model.add(layers.GlobalMaxPool1D())\n",
        "model.add(layers.Dense(10, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 280, 50)           2061850   \n",
            "                                                                 \n",
            " global_max_pooling1d (Globa  (None, 50)               0         \n",
            " lMaxPooling1D)                                                  \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                510       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,062,371\n",
            "Trainable params: 2,062,371\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ES889372KX82",
        "outputId": "6287a6ed-ec9a-41ff-b5d9-3fe18f806f3d"
      },
      "source": [
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=50,\n",
        "                    verbose=False,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    batch_size=10)\n",
        "loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
        "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Accuracy: 0.9194\n",
            "Testing Accuracy:  0.5665\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNsRbfDxx1JX"
      },
      "source": [
        "def create_embedding_matrix(filepath, word_index, embedding_dim):\n",
        "    vocab_size = len(word_index) + 1  # Adding again 1 because of reserved 0 index\n",
        "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "\n",
        "    with open(filepath) as f:\n",
        "        for line in f:\n",
        "            word, *vector = line.split()\n",
        "            if word in word_index:\n",
        "                idx = word_index[word] \n",
        "                embedding_matrix[idx] = np.array(\n",
        "                    vector, dtype=np.float32)[:embedding_dim]\n",
        "\n",
        "    return embedding_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ovcr45DBFDTi"
      },
      "source": [
        "### Convolutional Neural Networks (CNN)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJeO70lozxQT"
      },
      "source": [
        "clear_session()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6MTQgza4Onc",
        "outputId": "8b92dcbc-da36-455e-cde2-f7ffe84fe2e9"
      },
      "source": [
        "embedding_dim = 100\n",
        "\n",
        "model = Sequential()\n",
        "model.add(layers.Embedding(vocab_size, embedding_dim, input_length=max_len_tweet))\n",
        "model.add(layers.Conv1D(128, 5, activation='relu'))\n",
        "model.add(layers.GlobalMaxPooling1D())\n",
        "model.add(layers.Dense(10, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 280, 100)          4123700   \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 276, 128)          64128     \n",
            "                                                                 \n",
            " global_max_pooling1d (Globa  (None, 128)              0         \n",
            " lMaxPooling1D)                                                  \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                1290      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,189,129\n",
            "Trainable params: 4,189,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ccp0L_aoFlwW"
      },
      "source": [
        "tweets = df_tweets_raise['Tweet'].values\n",
        "y = df_tweets_raise['Raise'].values\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    tweets, \n",
        "    y, \n",
        "    test_size=0.25, \n",
        "    random_state=1000\n",
        "    )\n",
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(x_train)\n",
        "\n",
        "X_train = tokenizer.texts_to_sequences(x_train)\n",
        "X_test = tokenizer.texts_to_sequences(x_test)\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1  # Adding 1 because of reserved 0 index\n",
        "\n",
        "max_len_tweet = 280\n",
        "\n",
        "X_train = pad_sequences(X_train, padding='post', maxlen=max_len_tweet)\n",
        "X_test = pad_sequences(X_test, padding='post', maxlen=max_len_tweet)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7_jGfn2EFNU1",
        "outputId": "906bc713-f5a0-4e4a-af43-7ba5d13bb640"
      },
      "source": [
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=10,\n",
        "                    verbose=False,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    batch_size=10)\n",
        "loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
        "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Accuracy: 0.9090\n",
            "Testing Accuracy:  0.5545\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-cDQcPFhCkX"
      },
      "source": [
        "- Mudar a din para 25, 50, 100\n",
        "\n",
        "- alterar epochs\n",
        "\n",
        "- alterar batch size\n",
        "\n",
        "- alterar test_size"
      ]
    }
  ]
}